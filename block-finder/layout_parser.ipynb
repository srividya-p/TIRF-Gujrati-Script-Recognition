{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"3.png\")\n",
    "image = image[..., ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = lp.Detectron2LayoutModel('lp://PrimaLayout/mask_rcnn_R_50_FPN_3x/config',\n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "                                 label_map={1:\"TextRegion\", 2:\"ImageRegion\", 3:\"TableRegion\", 4:\"MathsRegion\", 5:\"SeparatorRegion\", 6:\"OtherRegion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pika/.virtualenvs/tifr-ass/lib/python3.8/site-packages/detectron2/structures/image_list.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/pika/.virtualenvs/tifr-ass/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "layout = model.detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'layoutparser.elements.layout.Layout'>\n",
      "TextBlock(block=Rectangle(x_1=59.027339935302734, y_1=2205.47412109375, x_2=1041.1748046875, y_2=2246.536865234375), text=None, id=None, type=TextRegion, parent=None, next=None, score=0.9999967813491821)\n"
     ]
    }
   ],
   "source": [
    "print(type(layout))\n",
    "print(layout[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blocks = lp.Layout([b for b in layout if b.type=='TextRegion']) #and b.score>0.91\n",
    "figure_blocks = lp.Layout([b for b in layout if b.type=='ImageRegion'])\n",
    "\n",
    "text_blocks = lp.Layout([b for b in text_blocks if not any(b.is_in(b_fig) for b_fig in figure_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "\n",
    "left_interval = lp.Interval(0, w/2*1.05, axis='x').put_on_canvas(image)\n",
    "\n",
    "left_blocks = text_blocks.filter_by(left_interval, center=True)\n",
    "left_blocks.sort(key = lambda b:b.coordinates[1])\n",
    "\n",
    "right_blocks = [b for b in text_blocks if b not in left_blocks]\n",
    "right_blocks.sort(key = lambda b:b.coordinates[1])\n",
    "\n",
    "text_blocks = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "new_image = lp.draw_box(image, text_blocks,\n",
    "            box_width=3,\n",
    "            show_element_id=True)\n",
    "print(type(new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=63\n",
    "x1, y1, x2, y2 = text_blocks[i].block.x_1, text_blocks[i].block.y_1, text_blocks[i].block.x_2, text_blocks[i].block.y_2\n",
    "cropped_img = image[int(y1):int(y2), int(x1):int(x2)]\n",
    "cv2.imwrite(\"cropped.png\", cropped_img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a8b2e740efe6c1a6fa66bdb2e3721401356c4248899c2268b8e28955c77b875"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tifr-ass': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
